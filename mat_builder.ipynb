{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\"data/train.csv\"\n",
    "\"data/pp1.csv\"\n",
    "\"data/mat.csv\"\n",
    "\"data/emb_mat.csv\"\n",
    "\"data/feat_mat.csv\"\n",
    "\"data/emb_mat_test.csv\"\n",
    "\n",
    "https://github.com/ryonion/kaggle_question_pair/tree/master/data\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import feature_generators as fg\n",
    "import preproc as pp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "reload(pp)\n",
    "reload(fg)\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression as lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_needed = 80000\n",
    "\n",
    "raw_file = \"data/train.csv\"\n",
    "pp_file  = \"data/pp1.csv\"\n",
    "mat_file = \"data/mat.csv\"\n",
    "raw_drop = [\"id\", \"question1\", \"question2\"]\n",
    "pos_tags = [\"ADJ\", \"ADP\", \"ADV\", \"CONJ\", \"DET\", \"NOUN\", \"NUM\", \"PRT\", \"PRON\", \"VERB\", \"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing 40000 data...\n",
      "pre-processed data shape: (80000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor ( koh-i-noor ) d...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely ? how can i solv...</td>\n",
       "      <td>find the remainder when [ math ] 23^ { 24 } [ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar , sal...</td>\n",
       "      <td>which fish would survive in salt water ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor ( koh-i-noor ) d...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely ? how can i solv...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar , sal...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3  find the remainder when [ math ] 23^ { 24 } [ ...             0  \n",
       "4           which fish would survive in salt water ?             0  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(raw_file, nrows = data_needed)\n",
    "try:\n",
    "    pproc = pd.read_csv(pp_file)\n",
    "    row_count = pproc.shape[0]\n",
    "    if row_count < data_needed:\n",
    "        print(\"Pre-Processing %d data...\"%(data_needed - row_count))\n",
    "        pproc = pproc.append(pp.stemmer(raw.loc[row_count:]))\n",
    "        pproc.to_csv(pp_file, index=False)\n",
    "\n",
    "except:\n",
    "    # don't have preproessed data yet.\n",
    "    print(\"Pre-Processing %d data...\"%(data_needed))\n",
    "    new_pp = pp.stemmer(raw)\n",
    "    new_pp.to_csv(pp_file, index=False)\n",
    "    \n",
    "print(\"pre-processed data shape:\", pd.read_csv(pp_file).shape)\n",
    "pd.read_csv(pp_file).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove(mat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(feat_func, pp_file, mat_file):\n",
    "    ff_name = pp.get_method_abbre(feat_func.__name__)\n",
    "    try:\n",
    "        df_pp = pd.read_csv(pp_file)\n",
    "        mat = pd.read_csv(mat_file)\n",
    "        \n",
    "        try:\n",
    "            # check if feature already exists\n",
    "            start_idx = mat[ff_name].last_valid_index()\n",
    "            print(start_idx+1 ,\"vs\", df_pp.shape[0])\n",
    "            if start_idx + 1 < df_pp.shape[0]:\n",
    "                print(\"extending %s col from start_idx: %d...\"%(ff_name,start_idx+1))\n",
    "                df_pp = df_pp.loc[start_idx+1:]\n",
    "                sub = '_sub_'\n",
    "                mat = mat.rename(index=str, columns={ff_name:sub})\n",
    "                cp_col = mat[sub][:start_idx+1].append(df_pp.apply(feat_func, axis=1, raw=True))\n",
    "                cp_col = cp_col.to_frame(ff_name)\n",
    "                cp_col.reset_index(drop=True, inplace=True)\n",
    "                mat.reset_index(drop=True, inplace=True)\n",
    "                new_df = cp_col.join(mat)\n",
    "                new_df = new_df.drop([sub], axis = 1)\n",
    "                new_df.to_csv(mat_file, index=False)\n",
    "                \n",
    "        # if feature doesn't alreay exist -> add a new col\n",
    "        except:\n",
    "            print(\"adding a new feature col\")\n",
    "            new_col = df_pp.apply(feat_func, axis=1, raw=True)\n",
    "            new_col = new_col.to_frame(ff_name)\n",
    "            new_df = pd.concat([mat,new_col],axis=1)\n",
    "            new_df.to_csv(mat_file, index=False)\n",
    "\n",
    "    # mat_file does not exist\n",
    "    except:\n",
    "        print(\"creating mat...\")\n",
    "        mat = pd.DataFrame()\n",
    "        mat[ff_name] = df_pp.apply(feat_func, axis=1, raw=True)\n",
    "        mat.to_csv(mat_file, index=False)\n",
    "\n",
    "    print(ff_name,\"applied, Mat shape: \", pd.read_csv(mat_file).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 vs 80000\n",
      "extending sp col from start_idx: 40000...\n",
      "sp applied, Mat shape:  (80000, 5)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "40000 vs 80000\n",
      "extending lcsp col from start_idx: 40000...\n",
      "lcsp applied, Mat shape:  (80000, 5)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "40000 vs 80000\n",
      "extending ifwi col from start_idx: 40000...\n",
      "ifwi applied, Mat shape:  (80000, 5)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "40000 vs 80000\n",
      "extending iisc col from start_idx: 40000...\n",
      "iisc applied, Mat shape:  (80000, 5)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "40000 vs 80000\n",
      "extending dw col from start_idx: 40000...\n",
      "dw applied, Mat shape:  (80000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dw</th>\n",
       "      <th>iisc</th>\n",
       "      <th>ifwi</th>\n",
       "      <th>lcsp</th>\n",
       "      <th>sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dw  iisc  ifwi      lcsp        sp\n",
       "0  0.071429   1.0   1.0  0.912000  0.500000\n",
       "1  0.185185   0.0   1.0  0.455172  0.444444\n",
       "2  0.153846   0.0   1.0  0.149254  0.230769\n",
       "3  0.187500   0.0   0.0  0.031496  0.125000\n",
       "4  0.333333   1.0   1.0  0.117647  0.250000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_feature(fg.shared_percentage, pp_file, mat_file, )\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "add_feature(fg.longest_common_substr_prop, pp_file, mat_file)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "add_feature(fg.is_first_word_identical, pp_file, mat_file)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "add_feature(fg.is_in_same_cat, pp_file, mat_file)\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "add_feature(fg.dif_wc, pp_file, mat_file)\n",
    "pd.read_csv(mat_file).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding embedding measurements into feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp</th>\n",
       "      <th>lcsp</th>\n",
       "      <th>ifwi</th>\n",
       "      <th>iisc</th>\n",
       "      <th>dw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sp      lcsp  ifwi  iisc        dw\n",
       "0  0.500000  0.912000     1     1  0.071429\n",
       "1  0.444444  0.455172     1     0  0.185185\n",
       "2  0.230769  0.149254     1     0  0.153846"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = pd.read_csv(mat_file)\n",
    "fm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>sim_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADJ       ADP  ADV  CONJ  DET      NOUN  NUM  PRT  PRON      VERB    X  \\\n",
       "0  0.0  0.969626  1.0   0.0  1.0  0.883462  0.0  0.0   1.0  1.000000  0.0   \n",
       "1  0.0  0.000000  0.0   0.0  1.0  0.667299  0.0  0.0   1.0  0.260665  0.0   \n",
       "2  0.0  0.355251  1.0   0.0  0.0  0.694622  0.0  0.0   0.0  0.602308  0.0   \n",
       "\n",
       "    sim_avg  \n",
       "0  0.975515  \n",
       "1  0.731991  \n",
       "2  0.663045  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = pd.read_csv(\"data/emb_mat.csv\")\n",
    "em.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = fm.join(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp</th>\n",
       "      <th>lcsp</th>\n",
       "      <th>ifwi</th>\n",
       "      <th>iisc</th>\n",
       "      <th>dw</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>sim_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sp      lcsp  ifwi  iisc        dw  ADJ       ADP  ADV  CONJ  DET  \\\n",
       "0  0.500000  0.912000     1     1  0.071429  0.0  0.969626  1.0   0.0  1.0   \n",
       "1  0.444444  0.455172     1     0  0.185185  0.0  0.000000  0.0   0.0  1.0   \n",
       "2  0.230769  0.149254     1     0  0.153846  0.0  0.355251  1.0   0.0  0.0   \n",
       "\n",
       "       NOUN  NUM  PRT  PRON      VERB    X   sim_avg  \n",
       "0  0.883462  0.0  0.0   1.0  1.000000  0.0  0.975515  \n",
       "1  0.667299  0.0  0.0   1.0  0.260665  0.0  0.731991  \n",
       "2  0.694622  0.0  0.0   0.0  0.602308  0.0  0.663045  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.to_csv(\"data/feat_mat.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 17)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"data/feat_mat.csv\")\n",
    "targ = pd.read_csv(pp_file)\n",
    "\n",
    "Y = targ['is_duplicate'][:40000]\n",
    "X = data\n",
    "\n",
    "XTR, xte, YTR, yte = train_test_split(X, Y, test_size=0.2, random_state=4242)\n",
    "xtr, xva, ytr, yva = train_test_split(XTR, YTR, test_size=0.2, random_state=4242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6165172001250802\n",
      "accuracy: 5272 / 8000 = 0.659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "logi = lr(C=1, penalty='l1').fit(XTR,YTR)\n",
    "predicted_LR = logi.predict(xte)\n",
    "print('AUC:', roc_auc_score(yte, predicted_LR))\n",
    "print('accuracy:', sum([int(int(l>0.5)==r) for l,r in zip(predicted_LR,yte)]), \"/\" ,len(predicted_LR), \"=\", \\\n",
    "      sum([int(int(l>0.5)==r) for l,r in zip(predicted_LR,yte)])/len(predicted_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='neg_log_loss',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search for best combination of C and penalty\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "C_range = 10.**np.arange(-2, 3)\n",
    "penalty_options = ['l1', 'l2']\n",
    "\n",
    "parameters = {'C':C_range, 'penalty':penalty_options}\n",
    "gs = GridSearchCV(lr(), parameters,cv=5, scoring='neg_log_loss')\n",
    "gs.fit(XTR,YTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5633145458600423\n",
      "{'C': 1.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0...ty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "pl = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(lr(penalty=\"l1\"))),\n",
    "  ('classification', model)\n",
    "])\n",
    "pl.fit(XTR, YTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pl, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6638249572738275"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(pl, open(\"models/lr_40000_full_feature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extreme gradient boost tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.288789\tvalid-error:0.305156\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 90 rounds.\n",
      "[10]\ttrain-error:0.278672\tvalid-error:0.295\n",
      "[20]\ttrain-error:0.277734\tvalid-error:0.292812\n",
      "[30]\ttrain-error:0.274063\tvalid-error:0.293281\n",
      "[40]\ttrain-error:0.272383\tvalid-error:0.290156\n",
      "[50]\ttrain-error:0.270156\tvalid-error:0.288125\n",
      "[60]\ttrain-error:0.268047\tvalid-error:0.284531\n",
      "[70]\ttrain-error:0.265508\tvalid-error:0.284531\n",
      "[80]\ttrain-error:0.263906\tvalid-error:0.281875\n",
      "[90]\ttrain-error:0.2625\tvalid-error:0.283437\n",
      "[100]\ttrain-error:0.261094\tvalid-error:0.282813\n",
      "[110]\ttrain-error:0.260078\tvalid-error:0.2825\n",
      "[120]\ttrain-error:0.25957\tvalid-error:0.282187\n",
      "[130]\ttrain-error:0.258359\tvalid-error:0.282187\n",
      "[140]\ttrain-error:0.258008\tvalid-error:0.2825\n",
      "[150]\ttrain-error:0.257109\tvalid-error:0.282656\n",
      "[160]\ttrain-error:0.256563\tvalid-error:0.280781\n",
      "[170]\ttrain-error:0.256172\tvalid-error:0.28\n",
      "[180]\ttrain-error:0.255352\tvalid-error:0.278906\n",
      "[190]\ttrain-error:0.254648\tvalid-error:0.279219\n",
      "[200]\ttrain-error:0.253086\tvalid-error:0.280156\n",
      "[210]\ttrain-error:0.252461\tvalid-error:0.278437\n",
      "[220]\ttrain-error:0.251484\tvalid-error:0.276563\n",
      "[230]\ttrain-error:0.250078\tvalid-error:0.275625\n",
      "[240]\ttrain-error:0.249023\tvalid-error:0.27625\n",
      "[250]\ttrain-error:0.248281\tvalid-error:0.275937\n",
      "[260]\ttrain-error:0.246875\tvalid-error:0.276406\n",
      "[270]\ttrain-error:0.246055\tvalid-error:0.276406\n",
      "[280]\ttrain-error:0.244961\tvalid-error:0.276094\n",
      "[290]\ttrain-error:0.243828\tvalid-error:0.274687\n",
      "[300]\ttrain-error:0.2425\tvalid-error:0.275625\n",
      "[310]\ttrain-error:0.240898\tvalid-error:0.274844\n",
      "[320]\ttrain-error:0.238906\tvalid-error:0.277344\n",
      "[330]\ttrain-error:0.237148\tvalid-error:0.275\n",
      "[340]\ttrain-error:0.235586\tvalid-error:0.275937\n",
      "[350]\ttrain-error:0.234727\tvalid-error:0.274687\n",
      "[360]\ttrain-error:0.233086\tvalid-error:0.275\n",
      "[370]\ttrain-error:0.230742\tvalid-error:0.275156\n",
      "[380]\ttrain-error:0.230234\tvalid-error:0.273906\n",
      "[390]\ttrain-error:0.228906\tvalid-error:0.272969\n",
      "[400]\ttrain-error:0.227773\tvalid-error:0.274219\n",
      "[410]\ttrain-error:0.226602\tvalid-error:0.273281\n",
      "[420]\ttrain-error:0.224844\tvalid-error:0.272969\n",
      "[430]\ttrain-error:0.223555\tvalid-error:0.274063\n",
      "[440]\ttrain-error:0.222344\tvalid-error:0.272969\n",
      "[450]\ttrain-error:0.220977\tvalid-error:0.273594\n",
      "[460]\ttrain-error:0.219727\tvalid-error:0.273281\n",
      "[470]\ttrain-error:0.217891\tvalid-error:0.273594\n",
      "[480]\ttrain-error:0.217461\tvalid-error:0.275156\n",
      "[490]\ttrain-error:0.215898\tvalid-error:0.275469\n",
      "[500]\ttrain-error:0.215117\tvalid-error:0.274687\n",
      "Stopping. Best iteration:\n",
      "[417]\ttrain-error:0.225742\tvalid-error:0.272656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'error'\n",
    "params['eta'] = 0.02\n",
    "params['max_leaf_nodes'] = 20\n",
    "params['subsample'] = 0.8\n",
    "\n",
    "d_train = xgb.DMatrix(xtr, label=ytr)\n",
    "d_valid = xgb.DMatrix(xva, label=yva)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=90, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AUC: 0.8028771909041527\n",
      "accuracy: 5761 / 8000 = 0.720125\n"
     ]
    }
   ],
   "source": [
    "d_te = xgb.DMatrix(xte)\n",
    "p_te = bst.predict(d_te)\n",
    "print('Original AUC:', roc_auc_score(yte, p_te))\n",
    "pp_train = []\n",
    "for i in p_te[:]:\n",
    "    if i > 0.5:\n",
    "        pp_train.append(1)\n",
    "    else:\n",
    "        pp_train.append(0)\n",
    "print('accuracy:', sum([int(l==r) for l,r in zip(pp_train,yte)]), \"/\" ,len(pp_train), \"=\", \\\n",
    "      sum([int(l==r) for l,r in zip(pp_train,yte)])/len(pp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.55% (0.55%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bst, open(\"models/xgb_40000_full_feature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 10), random_state=1)\n",
    "nn.fit(XTR, YTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6873816033955212\n",
      "accuracy: 5565 / 8000 = 0.695625\n"
     ]
    }
   ],
   "source": [
    "p_nn = nn.predict(xte)\n",
    "print('AUC:', roc_auc_score(yte, p_nn))\n",
    "print('accuracy:', sum([int(int(l>0.5)==r) for l,r in zip(p_nn,yte)]), \"/\" ,len(p_nn), \"=\", \\\n",
    "      sum([int(int(l>0.5)==r) for l,r in zip(p_nn,yte)])/len(p_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(nn, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051499387566397"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(nn, open(\"models/nn_40000_full_feature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "\n",
    "# ----------------training data----------------------\n",
    "\n",
    "x_arr = xtr.values\n",
    "y_arr = ytr\n",
    "\n",
    "row = x_arr.shape[0]\n",
    "col = x_arr.shape[1]\n",
    "\n",
    "x_arr = x_arr.reshape(row,col,1)\n",
    "\n",
    "# ----------------validation data----------------------\n",
    "\n",
    "xva_arr = xva.values\n",
    "yva_arr = yva.values\n",
    "\n",
    "row = xva_arr.shape[0]\n",
    "col = xva_arr.shape[1]\n",
    " \n",
    "x_va = xva_arr.reshape(row,col,1)\n",
    "y_va = yva_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 1), units=50)`\n",
      "  \"\"\"\n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n",
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/10\n",
      "25600/25600 [==============================] - 14s 566us/step - loss: 0.6033 - acc: 0.6449 - val_loss: 0.6059 - val_acc: 0.6547\n",
      "Epoch 2/10\n",
      "25600/25600 [==============================] - 16s 625us/step - loss: 0.5853 - acc: 0.6476 - val_loss: 0.5750 - val_acc: 0.6211\n",
      "Epoch 3/10\n",
      "25600/25600 [==============================] - 16s 622us/step - loss: 0.5622 - acc: 0.6518 - val_loss: 0.5387 - val_acc: 0.6728\n",
      "Epoch 4/10\n",
      "25600/25600 [==============================] - 16s 636us/step - loss: 0.5389 - acc: 0.6661 - val_loss: 0.5296 - val_acc: 0.6642\n",
      "Epoch 5/10\n",
      "25600/25600 [==============================] - 17s 651us/step - loss: 0.5307 - acc: 0.6736 - val_loss: 0.5496 - val_acc: 0.6550\n",
      "Epoch 6/10\n",
      "25600/25600 [==============================] - 17s 662us/step - loss: 0.5286 - acc: 0.6758 - val_loss: 0.5289 - val_acc: 0.6777\n",
      "Epoch 7/10\n",
      "25600/25600 [==============================] - 17s 671us/step - loss: 0.5264 - acc: 0.6730 - val_loss: 0.5266 - val_acc: 0.6831\n",
      "Epoch 8/10\n",
      "25600/25600 [==============================] - 17s 673us/step - loss: 0.5252 - acc: 0.6733 - val_loss: 0.5257 - val_acc: 0.6850\n",
      "Epoch 9/10\n",
      "25600/25600 [==============================] - 17s 670us/step - loss: 0.5257 - acc: 0.6716 - val_loss: 0.5236 - val_acc: 0.6873\n",
      "Epoch 10/10\n",
      "25600/25600 [==============================] - 17s 674us/step - loss: 0.5252 - acc: 0.6734 - val_loss: 0.5267 - val_acc: 0.6770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209d6bc0a58>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model=Sequential()\n",
    "\n",
    "# model.add(SimpleRNN(input_dim=1, output_dim=50))\n",
    "\n",
    "rnn_model.add(LSTM(input_dim=1, output_dim=50))\n",
    "rnn_model.add(Dense(output_dim=1, activation = \"sigmoid\"))\n",
    "rnn_model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rnn_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn_model.fit(x_arr, y_arr, validation_data=(x_va, y_va), nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 130us/step\n",
      "Elman RNN Test Accuracy: 67.062%\n"
     ]
    }
   ],
   "source": [
    "xte_arr = xte.values\n",
    "yte_arr = yte.values\n",
    "\n",
    "row = xte_arr.shape[0]\n",
    "col = xte_arr.shape[1]\n",
    " \n",
    "xte_arr = xte_arr.reshape(row,col,1)\n",
    "yte_arr = yte_arr    \n",
    "    \n",
    "scores = rnn_model.evaluate(xte_arr, yte_arr, verbose=1)\n",
    "print(\"Elman RNN Test Accuracy: %.3f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_model.save('models/rnn_40000_full_feature') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml\n",
    "np.random.seed(0)  # Resetting the seed in case you ran other stuff.\n",
    "n_bags = 20\n",
    "bags = []   # self.learners\n",
    "for l in range(n_bags):\n",
    "    # Each boosted data is the size of the original data. \n",
    "    Xi, Yi = ml.bootstrapData(XTR.values, YTR.values, XTR.shape[0])\n",
    "\n",
    "    # Train the model on that draw\n",
    "    tree = ml.dtree.treeClassify(Xi, Yi, minParent=2**6,maxDepth=25, nFeatures=6)\n",
    "    bags.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedTree(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        \"\"\"Constructs a BaggedTree class with a set of learners. \"\"\"\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self, X):\n",
    "        \"\"\"Predicts the probabilities with each bagged learner and average over the results. \"\"\"\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predictSoft(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BaggedTree(bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 6078/8000 75.97%\n"
     ]
    }
   ],
   "source": [
    "# test Accuracy\n",
    "rf_te_pred = bt.predictSoft(xte.values)\n",
    "\n",
    "pred = rf_te_pred[:,0]\n",
    "targ = yte\n",
    "bingo = sum([ int(t-p<0.5) for p,t in zip(pred,targ) ])\n",
    "print(\"Validation Accuracy: %d/%d %.2f%%\"%(bingo, len(targ), 100*bingo/len(targ)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bt, open(\"models/rf_40000_full_feature\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build stacked feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pickle.load(open(\"models/lr_40000_full_feature\", 'rb'))\n",
    "bst = pickle.load(open(\"models/xgb_40000_full_feature\", 'rb'))\n",
    "rnn_model = load_model(\"models/rnn_40000_full_feature\")\n",
    "nn = pickle.load(open(\"models/nn_40000_full_feature\", 'rb'))\n",
    "bt = pickle.load(open(\"models/rf_40000_full_feature\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_pred = pl.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bst_pred = bst.predict(xgb.DMatrix(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = X.values\n",
    "\n",
    "row = X_arr.shape[0]\n",
    "col = X_arr.shape[1]\n",
    " \n",
    "X_arr = X_arr.reshape(row,col,1)\n",
    "rnn_pred = rnn_model.predict(X_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = nn.predict(X)\n",
    "bt_pred = bt.predictSoft(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a model to make final predictions based on level-1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_stack = np.concatenate([bt_pred[:,0].reshape(40000,1), nn_pred.reshape(40000,1),\\\n",
    "                              bst_pred.reshape(40000,1),pl_pred.reshape(40000,1),rnn_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(simple_stack, open(\"data/40000_stacked_pred\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_xtr, s_xte, s_ytr, s_yte = train_test_split(simple_stack, Y, test_size=0.5, random_state=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = lr(C = 0.5, penalty = 'l1').fit(s_xtr, s_ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_slr = slr.predict(s_xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 18024/20000 90.12%\n"
     ]
    }
   ],
   "source": [
    "pred = pred_slr\n",
    "targ = s_yte\n",
    "bingo = sum([ int(t-p<0.5) for p,t in zip(pred,targ) ])\n",
    "print(\"Validation Accuracy: %d/%d %.2f%%\"%(bingo, len(targ), 100*bingo/len(targ)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(slr, simple_stack, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84164479, 0.845375  , 0.84175   , 0.8495    , 0.84148019])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a model to make final predictions based on all features and level-1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stack = np.concatenate([X, bt_pred[:,0].reshape(40000,1), nn_pred.reshape(40000,1),\\\n",
    "                              bst_pred.reshape(40000,1),pl_pred.reshape(40000,1),rnn_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 22)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_xtr, s_xte, s_ytr, s_yte = train_test_split(full_stack, Y, test_size=0.2, random_state=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslr = lr(C = 0.5, penalty = 'l1').fit(s_xtr, s_ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fslr = fslr.predict(s_xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 6800/8000 85.00%\n"
     ]
    }
   ],
   "source": [
    "pred = pred_fslr\n",
    "targ = s_yte\n",
    "bingo = sum([ int(t-p<0.5) for p,t in zip(pred,targ) ])\n",
    "print(\"Validation Accuracy: %d/%d %.2f%%\"%(bingo, len(targ), 100*bingo/len(targ)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lr(C = 0.5, penalty = 'l1'), full_stack, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84226972, 0.84575   , 0.84325   , 0.848875  , 0.84373047])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use another subset of original training data for evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(mat_file)[40000:]\n",
    "test_emb = pd.read_csv(\"data/emb_mat_test.csv\")\n",
    "test_Y = pd.read_csv(pp_file)[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comb = test.join(test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(test_comb)\n",
    "col_list[1], col_list[3] = col_list[3], col_list[1]\n",
    "col_list[0], col_list[4] = col_list[4], col_list[0]\n",
    "test_comb.columns = col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp</th>\n",
       "      <th>lcsp</th>\n",
       "      <th>ifwi</th>\n",
       "      <th>iisc</th>\n",
       "      <th>dw</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>sim_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sp  lcsp  ifwi      iisc        dw  ADJ       ADP  ADV  CONJ  DET  \\\n",
       "0  0.176471   0.0   1.0  0.786517  0.470588  0.0  0.000000  1.0   0.0  0.0   \n",
       "1  0.181818   0.0   1.0  0.817391  0.363636  1.0  0.922042  0.0   0.0  1.0   \n",
       "\n",
       "       NOUN  NUM  PRT  PRON  VERB    X   sim_avg  \n",
       "0  0.661447  0.0  0.0   0.0   1.0  0.0  0.887149  \n",
       "1  0.797719  0.0  0.0   1.0   1.0  0.0  0.953294  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comb.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pl_pred = pl.predict(test_comb)\n",
    "test_bst_pred = bst.predict(xgb.DMatrix(test_comb))\n",
    "\n",
    "test_X_arr = test_comb.values\n",
    "test_row = test_X_arr.shape[0]\n",
    "test_col = test_X_arr.shape[1]\n",
    "test_X_arr = test_X_arr.reshape(test_row,test_col,1)\n",
    "test_rnn_pred = rnn_model.predict(test_X_arr)\n",
    "\n",
    "test_nn_pred = nn.predict(test_comb)\n",
    "test_bt_pred = bt.predictSoft(test_comb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_stack = np.concatenate([test_comb, test_bt_pred[:,0].reshape(40000,1), test_nn_pred.reshape(40000,1),\\\n",
    "                              test_bst_pred.reshape(40000,1),test_pl_pred.reshape(40000,1),test_rnn_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_fslr = fslr.predict(test_full_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26134/40000 65.33%\n"
     ]
    }
   ],
   "source": [
    "pred = test_pred_fslr\n",
    "targ = test_Y['is_duplicate']\n",
    "bingo = sum([ int(t-p<0.5) for p,t in zip(pred,targ) ])\n",
    "print(\"Validation Accuracy: %d/%d %.2f%%\"%(bingo, len(targ), 100*bingo/len(targ)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
