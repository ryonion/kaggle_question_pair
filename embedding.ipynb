{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanz\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data/train.csv:\n",
    "https://github.com/ryonion/kaggle_question_pair/tree/master/data\n",
    "\n",
    "data/pp1.csv:\n",
    "https://github.com/ryonion/kaggle_question_pair/tree/master/data\n",
    "\n",
    "data/GoogleNews-vectors-negative300.bin.gz:\n",
    "https://github.com/mmihaltz/word2vec-GoogleNews-vectors\n",
    "\n",
    "'''\n",
    "\n",
    "import nltk, re, pprint\n",
    "# from nltk.book import *\n",
    "from nltk import word_tokenize\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk import pos_tag\n",
    "pos_idx = dict(ADJ=0, ADP=1, ADV=2, CONJ=3, DET=4, NOUN=5, NUM=6, PRT=7, PRON=8, VERB=9, X=10)\n",
    "labels = [\"ADJ\", \"ADP\", \"ADV\", \"CONJ\", \"DET\", \"NOUN\", \"NUM\", \"PRT\", \"PRON\", \"VERB\", \"X\", \"sim_avg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?']\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?']\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(list(train_data[\"question1\"])[0:2])\n",
    "print(list(train_data[\"question2\"])[0:2])\n",
    "\n",
    "q1 = [s.replace(\",\",' ').split() for s in train_data[\"question1\"] if type(s) == str]\n",
    "q2 = [s.replace(\",\",' ').split() for s in train_data[\"question2\"] if type(s) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w2v = Word2Vec(q1+q2)\n",
    "# w2v.save(\"emb_tr\")\n",
    "\n",
    "# type(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2x = Word2Vec.load(\"emb_tr\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = word2vec.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pproc = pd.read_csv(\"data/pp1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pproc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idx = dict(ADJ=0, ADP=1, ADV=2, CONJ=3, DET=4, NOUN=5, NUM=6, PRT=7, PRON=8, VERB=9, X=10)\n",
    "\n",
    "def parts_of_speech(s):\n",
    "        if type(s) == str:                                                 \n",
    "                tokens = word_tokenize(s)\n",
    "        else:\n",
    "                tokens = s                                                 \n",
    "        tokens_and_tags = pos_tag(tokens, tagset = \"universal\")\n",
    "        return(tokens_and_tags)\n",
    "\n",
    "def sent_embedding(pos_li, vec_size):\n",
    "    pos_groups = [ np.zeros((vec_size)) for i in range(len(pos_idx)) ]\n",
    "    for word, pos in pos_li:\n",
    "        if pos != '.':\n",
    "            if word in word2vec.vocab:\n",
    "                pos_groups[pos_idx[pos]] += word2vec.word_vec(word)\n",
    "    return pos_groups\n",
    "\n",
    "def sent_cos_similarity(pos_group1, pos_group2):\n",
    "    ret = []\n",
    "    for i, _ in enumerate(pos_group1):\n",
    "        ret.append((cosine_similarity(pos_group1[i].reshape(1, -1), pos_group2[i].reshape(1, -1)))[0][0])\n",
    "    return tuple(ret)\n",
    "\n",
    "def sent_similarity_group(row):\n",
    "    s1 = row[\"question1\"]\n",
    "    s2 = row[\"question2\"]\n",
    "    \n",
    "    pos_li_1 = parts_of_speech(s1)\n",
    "    pos_li_2 = parts_of_speech(s2)\n",
    "    \n",
    "    # assign the words in a sentence into each of the 11 POS groups\n",
    "    # substitute each word in each POS group with the word's embedding vector\n",
    "    # sum the vectors in each POS group of a sentence\n",
    "    # so we will have a list of 11 vectors for each sentence\n",
    "    \n",
    "    emb_list_1 = sent_embedding(pos_li_1, vec_size)\n",
    "    emb_list_2 = sent_embedding(pos_li_2, vec_size)\n",
    "    # compute the cosine_similarity of the corresponding groups in the two sentences\n",
    "    # so we will have a list of 11 cosine_similarity measures.\n",
    "\n",
    "    cos_sim = sent_cos_similarity(emb_list_1, emb_list_2)\n",
    "    temp = sum(int(i>0) for i in cos_sim)\n",
    "    if temp == 0: temp = 1\n",
    "    perc = sum(cos_sim) / temp\n",
    "    return cos_sim + (perc,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test sent_similarity_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"hello good morning\",\"hello good night\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(example, index=['question1','question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADJ', 1.0000000000000002), ('ADP', 0.0), ('ADV', 0.9999999999999999), ('CONJ', 0.0), ('DET', 0.0), ('NOUN', 0.6452910623105599), ('NUM', 0.0), ('PRT', 0.0), ('PRON', 0.0), ('VERB', 0.0), ('X', 0.0), ('sim_avg', 0.8817636874368532)]\n"
     ]
    }
   ],
   "source": [
    "print([ (a,b) for (a,b) in zip(labels, sent_similarity_group(s))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pproc[40000:].apply(sent_similarity_group,axis=1, raw=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000    (0.0, 0.0, 1.0000000000000002, 0.0, 0.0, 0.661...\n",
       "40001    (0.9999999999999999, 0.9220422233390738, 0.0, ...\n",
       "40002    (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.311...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_li = emb.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(emb_li, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"data/emb_mat_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
